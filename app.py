import streamlit as st
import google.generativeai as genai

st.set_page_config(page_title="OskemenGuide AI", page_icon="üèîÔ∏è")
st.title("üèîÔ∏è OskemenGuide AI")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á
if "GEMINI_KEY" not in st.secrets:
    st.error("–î–æ–±–∞–≤—å—Ç–µ GEMINI_KEY –≤ Secrets!")
    st.stop()

genai.configure(api_key=st.secrets["GEMINI_KEY"])

# –§—É–Ω–∫—Ü–∏—è —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º –ø—É—Ç–µ–º –∫ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    try:
        # –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö –Ω—É–∂–Ω–æ –ø–∏—Å–∞—Ç—å 'models/gemini-1.5-flash'
        # –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–æ—Å—Ç–æ 'gemini-1.5-flash'
        # –ü—Ä–æ–±—É–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞
        model = genai.GenerativeModel('models/gemini-1.5-flash')
        model.generate_content("test")
        return model
    except:
        return genai.GenerativeModel('gemini-1.5-flash')

model = load_model()

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("–°–ø—Ä–æ—Å–∏ –ø—Ä–æ –í–ö–û..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            # –¢–≤–æ–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            full_prompt = f"–¢—ã –≥–∏–¥ –ø–æ –í–æ—Å—Ç–æ—á–Ω–æ–º—É –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—É. –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å: {prompt}. –í –∫–æ–Ω—Ü–µ –Ω–∞–ø–æ–º–Ω–∏ –±–µ—Ä–µ—á—å –ø—Ä–∏—Ä–æ–¥—É."
            response = model.generate_content(full_prompt)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ API: {e}")
